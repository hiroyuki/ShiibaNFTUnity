#pragma kernel ProcessDepthPixels

// Platform-specific depth data type
#if defined(SHADER_API_METAL)
    #define DEPTH_TYPE uint
    #define DEPTH_SIZE 4
#else
    #define DEPTH_TYPE ushort
    #define DEPTH_SIZE 2
#endif

struct CameraParameters
{
    float fx_d, fy_d, cx_d, cy_d;
    float fx_c, fy_c, cx_c, cy_c;
};

struct VertexData
{
    float3 vertex;
    float4 color;
    int isValid;
    
    static const int SIZE = 3 * 4 + 4 * 4 + 1 * 4; // 3 floats + 4 floats + 1 int = 32 bytes
};

RWStructuredBuffer<DEPTH_TYPE> depthValues;
RWStructuredBuffer<float4> colorPixels;
RWStructuredBuffer<float2> depthUndistortLUT;
RWStructuredBuffer<VertexData> outputVertices;
RWStructuredBuffer<int> validCount;

float4x4 rotationMatrix;
float3 translation;
float depthScaleFactor;
float depthBias;
float fx_d, fy_d, cx_d, cy_d; // Depth camera parameters
float fx_c, fy_c, cx_c, cy_c; // Color camera parameters
float4 colorDistortion; // k1, k2, p1, p2 (first 4 values)
float4 colorDistortion2; // k3, k4, k5, k6 (remaining values)
int depthWidth;
int depthHeight;
int colorWidth;
int colorHeight;
bool useOpenCVLUT;
float4x4 boundingVolumeTransform;
float4x4 boundingVolumeInverseTransform;
float4x4 depthViewerTransform;
bool showAllPoints;
bool hasBoundingVolume;

float2 DistortColorProjection(float x_norm, float y_norm)
{
    float k1 = colorDistortion.x, k2 = colorDistortion.y, k3 = colorDistortion2.x;
    float k4 = colorDistortion2.y, k5 = colorDistortion2.z, k6 = colorDistortion2.w;
    float p1 = colorDistortion.z, p2 = colorDistortion.w;

    float r2 = x_norm * x_norm + y_norm * y_norm;
    float r4 = r2 * r2;
    float r6 = r4 * r2;

    float radial = 1 + k1 * r2 + k2 * r4 + k3 * r6;
    float x_d = x_norm * radial + 2 * p1 * x_norm * y_norm + p2 * (r2 + 2 * x_norm * x_norm);
    float y_d = y_norm * radial + 2 * p2 * x_norm * y_norm + p1 * (r2 + 2 * y_norm * y_norm);

    float u = fx_c * x_d + cx_c;
    float v = fy_c * y_d + cy_c;

    return float2(u, v);
}

bool IsPointInBoundingVolume(float3 worldPoint)
{
    if (!hasBoundingVolume) return true;

    float4 localPoint4 = mul(boundingVolumeInverseTransform, float4(worldPoint, 1.0));
    float3 localPoint = localPoint4.xyz;

    return abs(localPoint.x) <= 0.5 && abs(localPoint.y) <= 0.5 && abs(localPoint.z) <= 0.5;
}

[numthreads(64,1,1)]
void ProcessDepthPixels (uint3 id : SV_DispatchThreadID)
{
    uint i = id.x;
    uint totalPixels = depthWidth * depthHeight;
    
    if (i >= totalPixels) return;
    
    int x = i % depthWidth;
    int y = i / depthWidth;
    
    // Apply depth bias correction and scale factor
    float correctedDepth = depthValues[i] + depthBias;
    float z = correctedDepth * (depthScaleFactor / 1000.0);
    if (z <= 0) 
    {
        outputVertices[i].isValid = 0;
        return;
    }
    
    float px, py;
    
    if (useOpenCVLUT)
    {
        // Method 1: OpenCV-generated undistortion LUT
        float2 rayCoords = depthUndistortLUT[x + y * depthWidth];
        px = rayCoords.x * z;
        py = rayCoords.y * z;
    }
    else
    {
        // Method 2: Simple pinhole camera model
        px = (x - cx_d) * z / fx_d;
        py = (y - cy_d) * z / fy_d;
    }
    
    float3 dPoint = float3(px, py, z);
    float3 cPoint = mul(rotationMatrix, dPoint) + translation;
    
    // Skip points behind camera
    if (cPoint.z <= 0)
    {
        outputVertices[i].isValid = 0;
        return;
    }
    
    float x_norm = cPoint.x / cPoint.z;
    float y_norm = cPoint.y / cPoint.z;
    float2 colorPixel = DistortColorProjection(x_norm, y_norm);
    
    int ui = (int)round(colorPixel.x);
    int vi = colorHeight - 1 - (int)round(colorPixel.y);
    
    float4 color = float4(0, 0, 0, 1); // Default: black
    bool hasValidColor = false;
    
    if (ui >= 0 && ui < colorWidth && vi >= 0 && vi < colorHeight)
    {
        int colorIdx = vi * colorWidth + ui;
        if (colorIdx >= 0 && colorIdx < colorWidth * colorHeight)
        {
            color = colorPixels[colorIdx];
            // Check if color is not completely black
            hasValidColor = color.r > 0 || color.g > 0 || color.b > 0;
        }
    }
    
    // Convert cPoint to world coordinates for bounding volume check
    float4 worldPoint4 = mul(depthViewerTransform, float4(cPoint, 1.0));
    float3 worldPoint = worldPoint4.xyz;
    
    // Only add points with valid colors and within bounding volume
    bool withinBounds = showAllPoints || IsPointInBoundingVolume(worldPoint);
    
    if (hasValidColor && withinBounds)
    {
        outputVertices[i].vertex = cPoint;
        outputVertices[i].color = color;
        outputVertices[i].isValid = 1;
        InterlockedAdd(validCount[0], 1);
    }
    else
    {
        outputVertices[i].isValid = 0;
    }
}